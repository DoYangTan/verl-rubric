import openai
import concurrent.futures
import time

# é…ç½®ï¼šæŒ‡å‘ä½ çš„ Forwarder ç«¯å£ 9099
client = openai.OpenAI(
    base_url="http://localhost:9099/v1",
    api_key="EMPTY",
)

# ä½ çš„æ¨¡å‹åç§°
MODEL_NAME = "gpt-oss-120b" 

def send_request(idx):
    try:
        start_time = time.time()
        
        # --- ä¿®æ”¹ 1: ä¼˜åŒ– Promptï¼Œå°è¯•æŠ‘åˆ¶è¿‡é•¿çš„æ¨ç† ---
        prompt_content = "Hi. Answer briefly."
        
        completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "user", "content": prompt_content}
            ],
            # --- ä¿®æ”¹ 2: å…³é”®ï¼å¿…é¡»å¢åŠ  Token æ•°ï¼Œå¦åˆ™æ¨ç†æ¨¡å‹è¿˜æ²¡æƒ³å®Œå°±è¢«æˆªæ–­äº† ---
            max_tokens=200, 
            temperature=0.7,
        )
        duration = time.time() - start_time
        
        # è·å–è¿”å›å†…å®¹
        message = completion.choices[0].message
        content = message.content
        
        # --- ä¿®æ”¹ 3: å¦‚æœ content ä¸ºç©ºï¼Œå°è¯•è¯»å– reasoning_content (æ¨ç†å†…å®¹) ---
        # å¾ˆå¤šæ–°æ¨¡å‹æŠŠæ€ç»´é“¾æ”¾åœ¨ reasoning_content å­—æ®µé‡Œ
        if not content and hasattr(message, 'reasoning_content') and message.reasoning_content:
            final_output = f"[æ€è€ƒè¿‡ç¨‹] {message.reasoning_content[:50]}..."
            status_icon = "ğŸ§ " # è¡¨ç¤ºè¿”å›çš„æ˜¯æ€è€ƒè¿‡ç¨‹
        elif content:
            final_output = content.strip()
            status_icon = "âœ…"
        else:
            final_output = "âŒ ç©ºå†…å®¹ (Tokenå¯èƒ½ä¸è¶³)"
            status_icon = "âš ï¸"

        print(f"{status_icon} è¯·æ±‚ #{idx} å®Œæˆ! è€—æ—¶: {duration:.2f}s | å›å¤: {final_output}")
        return True
        
    except Exception as e:
        print(f"âŒ è¯·æ±‚ #{idx} å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    total_requests = 20
    concurrency = 5

    print(f"ğŸš€ å¼€å§‹æµ‹è¯•: å‘ç«¯å£ 9099 å‘é€ {total_requests} ä¸ªè¯·æ±‚ (å¹¶å‘æ•°: {concurrency})...")
    
    start_all = time.time()
    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrency) as executor:
        futures = [executor.submit(send_request, i) for i in range(total_requests)]
        concurrent.futures.wait(futures)
    
    print(f"\nğŸ æµ‹è¯•ç»“æŸ! æ€»è€—æ—¶: {time.time() - start_all:.2f}s")